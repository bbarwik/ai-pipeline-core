"""Tests for LLM client retry and structured generation."""

import asyncio
from unittest.mock import AsyncMock, MagicMock, patch

import pytest
from pydantic import BaseModel

from ai_pipeline_core.exceptions import LLMError
from ai_pipeline_core.llm import AIMessages, ModelOptions, generate
from ai_pipeline_core.llm.client import _generate_with_retry  # type: ignore[reportPrivateUsage]


class ExampleModel(BaseModel):
    """Example model for structured generation."""

    field1: str
    field2: int


class TestRetryLogic:
    """Test retry logic for LLM generation."""

    @pytest.mark.asyncio
    async def test_retry_on_timeout(self):
        """Test retry on timeout with exponential backoff."""
        with patch("ai_pipeline_core.llm.client.AsyncOpenAI") as mock_client_class:
            mock_client = MagicMock()
            mock_client_class.return_value.__aenter__.return_value = mock_client

            # First two calls fail, third succeeds
            AsyncMock(
                side_effect=[
                    asyncio.TimeoutError("Timeout 1"),
                    asyncio.TimeoutError("Timeout 2"),
                    MagicMock(
                        choices=[MagicMock(message=MagicMock(content="Success"))],
                        id="test-id",
                        object="chat.completion",
                        created=1234567890,
                        model="test-model",
                        usage=None,
                    ),
                ]
            )
            mock_client.chat.completions.with_raw_response.create = MagicMock(
                return_value=MagicMock(
                    parse=MagicMock(
                        return_value=MagicMock(
                            choices=[MagicMock(message=MagicMock(content="Success"))],
                            id="test-id",
                            object="chat.completion",
                            created=1234567890,
                            model="test-model",
                            usage=None,
                        )
                    ),
                    headers=MagicMock(items=MagicMock(return_value=[])),
                )
            )

            # Mock sleep to avoid delays
            with patch("asyncio.sleep") as mock_sleep:
                mock_sleep.return_value = None

                # This should eventually succeed after retries
                AIMessages(["Test"])
                ModelOptions(retries=3, retry_delay_seconds=1)

                # Note: Can't easily test the actual retry logic without more complex mocking
                # This is a simplified test structure

    @pytest.mark.asyncio
    async def test_exhausted_retries(self):
        """Test that LLMError is raised when all retries are exhausted."""
        with patch("ai_pipeline_core.llm.client.AsyncOpenAI") as mock_client_class:
            mock_client = MagicMock()
            mock_client_class.return_value.__aenter__.return_value = mock_client

            # All calls fail
            mock_client.chat.completions.with_raw_response.create.side_effect = (
                asyncio.TimeoutError("Timeout")
            )

            with patch("asyncio.sleep"):
                messages = AIMessages(["Test"])
                options = ModelOptions(retries=2, retry_delay_seconds=1)

                with pytest.raises(LLMError) as exc_info:
                    await _generate_with_retry("test-model", AIMessages(), messages, options)

                assert "Exhausted all retry attempts" in str(exc_info.value)

    @pytest.mark.asyncio
    async def test_no_model_raises_error(self):
        """Test that missing model raises ValueError."""
        messages = AIMessages(["Test"])

        with pytest.raises(ValueError) as exc_info:
            await _generate_with_retry("", AIMessages(), messages, ModelOptions())

        assert "Model must be provided" in str(exc_info.value)

    @pytest.mark.asyncio
    async def test_no_messages_or_context_raises_error(self):
        """Test that having neither messages nor context raises ValueError."""
        with pytest.raises(ValueError) as exc_info:
            await _generate_with_retry("test-model", AIMessages(), AIMessages(), ModelOptions())

        assert "Either context or messages must be provided" in str(exc_info.value)


class TestStructuredGeneration:
    """Test structured generation with Pydantic models."""

    @pytest.mark.asyncio
    async def test_generate_delegates_to_retry(self):
        """Test that generate properly delegates to _generate_with_retry."""
        with patch("ai_pipeline_core.llm.client._generate_with_retry") as mock_retry:
            mock_response = MagicMock()
            mock_retry.return_value = mock_response

            context = AIMessages(["Context"])
            messages = AIMessages(["Message"])
            options = ModelOptions()

            result = await generate(
                model="test-model", context=context, messages=messages, options=options
            )

            assert result == mock_response
            mock_retry.assert_called_once_with("test-model", context, messages, options)
